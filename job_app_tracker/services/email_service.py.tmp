import os
import base64
import json
import re
import requests
import imaplib
import email
from email.header import decode_header
import ssl
from datetime import datetime, timedelta
import logging
import time
import os.path
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import Flow
from googleapiclient.discovery import build
from email.mime.text import MIMEText
from bs4 import BeautifulSoup
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from job_app_tracker.config.mongodb import mongo
from bson.objectid import ObjectId
from werkzeug.security import generate_password_hash, check_password_hash
import html2text
from flask import current_app
import threading
import csv
from pathlib import Path
from job_app_tracker.config.logging import logger

# Create logs directory if it doesn't exist
Path('logs').mkdir(parents=True, exist_ok=True)
Path('logs/analysis').mkdir(parents=True, exist_ok=True)

# Download NLTK resources if not already downloaded
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    try:
        nltk.download('punkt', quiet=True)
    except:
        print("Warning: Could not download NLTK punkt. Email content analysis may be limited.")
    
try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    try:
        nltk.download('stopwords', quiet=True)
    except:
        print("Warning: Could not download NLTK stopwords. Email content analysis may be limited.")

# Constants
GMAIL_SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']
OUTLOOK_SCOPES = ['offline_access', 'Mail.Read']
YAHOO_IMAP_SERVER = 'imap.mail.yahoo.com'
YAHOO_IMAP_PORT = 993

# Enhanced keywords for job application detection
APPLICATION_KEYWORDS = {
    'strong_indicators': [
        'thank you for applying', 'application has been received', 'application received',
        'application submitted', 'thank you for your application', 'we have received your application',
        'submission received', 'thank you for your interest', 'application complete',
        'successfully applied', 'application has been submitted', 'interview invitation',
        'schedule an interview', 'interview request', 'interview confirmation',
        'interview schedule', 'interview details', 'interview with', 'invite you to interview',
        'interview process', 'job offer', 'offer letter', 'pleased to offer', 'formal offer',
        'compensation', 'salary', 'benefits', 'start date', 'onboarding', 'welcome to the team',
        'join our team', 'employment offer'
    ],
    'general_indicators': [
        'application', 'job', 'position', 'resume', 'cv', 'candidate', 'opportunity',
        'interview', 'hiring', 'recruitment', 'talent', 'career', 'employment',
        'role', 'job posting', 'career opportunity', 'job description', 'job requisition',
        'job title', 'job opening', 'job vacancy', 'job id', 'req id', 'requisition'
    ],
    'status_indicators': {
        'applied': [
            'thank you for applying', 'application has been received', 'application received',
            'application submitted', 'thank you for your application', 'we have received your application',
            'submission received', 'thank you for your interest', 'application complete',
            'successfully applied', 'application has been submitted'
        ],
        'in_progress': [
            'reviewing', 'under review', 'being considered', 'in consideration', 'processing',
            'application is being reviewed', 'currently reviewing', 'assessment', 'evaluation',
            'screening', 'pre-screening', 'application process', 'next steps', 'under consideration',
            'being reviewed', 'initial review', 'preliminary review', 'application is in progress',
            'moving forward with your application', 'coding challenge', 'technical assessment',
            'skills assessment', 'online assessment', 'take-home assignment', 'questionnaire',
            'additional information needed'
        ],
        'interview': [
            'schedule an interview', 'interview invitation', 'interview request',
            'interview confirmation', 'interview schedule', 'interview details',
            'interview with', 'invite you to interview', 'interview process',
            'phone interview', 'video interview', 'in-person interview', 'meeting',
            'confirm interview', 'interview invitation', 'would like to speak with you',
            'interview process', 'schedule a time', 'virtual interview', 'zoom interview',
            'teams meeting', 'google meet', 'phone screen', 'technical interview',
            'hiring manager', 'panel interview', 'second interview', 'final interview',
            'follow-up interview', 'interview with the team', 'meet the team'
        ],
        'rejected': [
            'unfortunately', 'not selected', 'other candidates', 'not moving forward',
            'not proceeding', 'regret', 'we will be going with other candidates',
            'not a fit', 'regret to inform you', 'move forward with other candidates',
            'application not successful', 'decline', 'rejection', 'thank you for your interest, but',
            'we have decided', 'we have chosen', 'we have filled', 'position has been filled',
            'decided not to proceed', 'pursuing other candidates', 'not successful',
            'we are unable to offer', 'we cannot offer', 'we regret to inform you',
            'after careful consideration', 'we appreciate your interest, however',
            'we have identified candidates', 'we will not be proceeding'
        ],
        'offer': [
            'job offer', 'offer letter', 'pleased to offer', 'formal offer',
            'compensation', 'salary', 'benefits', 'start date', 'onboarding',
            'welcome to the team', 'join our team', 'employment offer',
            'we are delighted', 'we are pleased', 'we would like to offer',
            'offer of employment', 'employment offer', 'offer details',
            'accept the offer', 'offer acceptance', 'employment contract',
            'starting salary', 'compensation package', 'benefits package',
            'contingent offer', 'conditional offer', 'official offer'
        ]
    }
}

# Company name patterns
COMPANY_PATTERNS = [
    # Existing patterns
    r'(?:from|at|with)\s+([A-Z][A-Za-z0-9\s&]+(?:Inc|LLC|Ltd|Corp|Corporation|Company))',
    r'([A-Z][A-Za-z0-9\s&]+(?:Inc|LLC|Ltd|Corp|Corporation|Company))',
    r'(?:team|recruiting|talent|hr)(?:\s+at)?\s+([A-Z][A-Za-z0-9\s&]+)',
    r'(?:best regards|regards|sincerely|thanks),?\s*([A-Z][A-Za-z0-9\s&]+(?:Inc|LLC|Ltd|Corp|Corporation|Company))',
    r'([A-Z][A-Za-z0-9\s&]+(?:Inc|LLC|Ltd|Corp|Corporation|Company))\s*$',
    
    # New patterns - more flexible company name detection
    r'(?:from|at|with)\s+([A-Z][A-Za-z0-9\s&\.\-\']+)(?:\s|$|\.|,)',
    r'(?:team at|team of|join us at|join|work for|apply to|apply with)\s+([A-Z][A-Za-z0-9\s&\.\-\']+)(?:\s|$|\.|,)',
    r'(?:careers at|jobs at|opportunities at|employment at)\s+([A-Z][A-Za-z0-9\s&\.\-\']+)(?:\s|$|\.|,)',
    r'(?:best regards|regards|sincerely|thanks),?\s*\n*([A-Z][A-Za-z0-9\s&\.\-\']+)(?:\s|$|\.|,)',
    r'(?:^|\n)([A-Z][A-Za-z0-9\s&\.\-\']{2,30})(?:\s+Team|\s+Recruiting|\s+Talent|\s+HR|\s+Careers)',
    r'(?:on behalf of|representing)\s+([A-Z][A-Za-z0-9\s&\.\-\']+)(?:\s|$|\.|,)',
    r'(?:interview|opportunity|position) (?:with|at)\s+([A-Z][A-Za-z0-9\s&\.\-\']+)(?:\s|$|\.|,)',
    r'(?:application to|application with|application for|interest in)\s+([A-Z][A-Za-z0-9\s&\.\-\']+)(?:\s|$|\.|,)'
]

# Position patterns
POSITION_PATTERNS = [
    r'(?:position|role|job|opportunity)(?:\s+for)?\s+(?:of\s+)?([A-Za-z0-9\s]+(?:Developer|Engineer|Manager|Designer|Analyst|Specialist|Director|Coordinator|Assistant|Administrator|Consultant|Architect|Lead|Senior|Junior|Principal|Staff|Head|Chief|Officer|President|Vice President|VP|CEO|CTO|CFO|COO|CIO|Founder|Co-founder|Partner|Associate|Intern|Trainee|Apprentice))',
    r'([A-Za-z0-9\s]+(?:Developer|Engineer|Manager|Designer|Analyst|Specialist|Director|Coordinator|Assistant|Administrator|Consultant|Architect|Lead|Senior|Junior|Principal|Staff|Head|Chief|Officer|President|Vice President|VP|CEO|CTO|CFO|COO|CIO|Founder|Co-founder|Partner|Associate|Intern|Trainee|Apprentice))\s+(?:position|role|job|opportunity)',
    r'(?:applying|application|candidacy)\s+for\s+([A-Za-z0-9\s]+)',
    r'(?:looking for|seeking|hiring)\s+([A-Za-z0-9\s]+)',
    r'([A-Za-z0-9\s]+(?:Developer|Engineer|Manager|Designer|Analyst|Specialist|Director|Coordinator|Assistant|Administrator|Consultant|Architect|Lead|Senior|Junior|Principal|Staff|Head|Chief|Officer|President|Vice President|VP|CEO|CTO|CFO|COO|CIO|Founder|Co-founder|Partner|Associate|Intern|Trainee|Apprentice))(?:\s+at|\s+with|\s+for)?\s+[A-Za-z0-9\s]+',
    r'[A-Za-z0-9\s]+(?:\s+at|\s+with|\s+for)?\s+([A-Za-z0-9\s]+(?:Developer|Engineer|Manager|Designer|Analyst|Specialist|Director|Coordinator|Assistant|Administrator|Consultant|Architect|Lead|Senior|Junior|Principal|Staff|Head|Chief|Officer|President|Vice President|VP|CEO|CTO|CFO|COO|CIO|Founder|Co-founder|Partner|Associate|Intern|Trainee|Apprentice))'
]

class EmailService:
    _cache = {}
    _cache_ttl = 3600  # 1 hour in seconds
    _email_cache = {}  # Cache for processed emails
    _email_cache_ttl = 7 * 24 * 3600  # 7 days in seconds
    _analysis_cache = {}  # Cache for email analysis results

    @staticmethod
    def _init_cache():
        """Initialize the cache collections in MongoDB"""
        try:
            # Create TTL index for analysis cache
            mongo.db.analysis_cache.create_index(
                "created_at",
                expireAfterSeconds=EmailService._cache_ttl
            )
            logger.info("TTL index created successfully")
        except Exception as e:
            logger.error(f"Error creating TTL index: {str(e)}")

    @staticmethod
    def _get_cached_email(email_id, user_id):
        """Get cached email analysis result"""
        try:
            cache_key = f"{user_id}_{email_id}"
            cached_data = EmailService._analysis_cache.get(cache_key)
            if cached_data:
                return cached_data
            return None
        except Exception as e:
            logger.error(f"Error getting cached email: {str(e)}")
            return None

    @staticmethod
    def _cache_email(email_id, user_id, analysis_data):
        """Cache email analysis result"""
        try:
            cache_key = f"{user_id}_{email_id}"
            EmailService._analysis_cache[cache_key] = analysis_data
        except Exception as e:
            logger.error(f"Error caching email: {str(e)}")

    @staticmethod
    def _clear_cache():
        """Clear all caches"""
        try:
            EmailService._cache.clear()
            EmailService._email_cache.clear()
            EmailService._analysis_cache.clear()
            logger.info("Cache cleared successfully")
        except Exception as e:
            logger.error(f"Error clearing cache: {str(e)}")

    @staticmethod
    def _cleanup_expired_cache():
        """Clean up expired cache entries"""
        try:
            current_time = time.time()
            # Clean up email cache
            EmailService._email_cache = {
                k: v for k, v in EmailService._email_cache.items()
                if current_time - v.get('timestamp', 0) < EmailService._email_cache_ttl
            }
            # Clean up analysis cache
            EmailService._analysis_cache = {
                k: v for k, v in EmailService._analysis_cache.items()
                if current_time - v.get('timestamp', 0) < EmailService._cache_ttl
            }
        except Exception as e:
            logger.error(f"Error cleaning up cache: {str(e)}")

    @staticmethod
    def _create_analysis_log(user_id, scan_id):
        """Create a new analysis log file for a scan session"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        log_file = f'job_app_tracker/logs/analysis/scan_{user_id}_{timestamp}_{scan_id}.csv'
        
        # Create CSV file with headers
        with open(log_file, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([
                'Email ID', 'Subject', 'From', 'Date', 'Is Job Related',
                'Company', 'Position', 'Status', 'Job URL', 'Deadline',
                'Notes', 'Confidence', 'Analysis Method', 'Matched Keywords',
                'Analysis Time'
            ])
        
        return log_file

    @staticmethod
    def _log_email_analysis(log_file, analysis_data):
        """Log email analysis results to CSV file"""
        try:
            with open(log_file, 'a', newline='') as f:
                writer = csv.writer(f)
                writer.writerow([
                    analysis_data.get('email_id', ''),
                    analysis_data.get('subject', ''),
                    analysis_data.get('from_email', ''),
                    analysis_data.get('date', ''),
                    analysis_data.get('is_job_related', False),
                    analysis_data.get('company', ''),
                    analysis_data.get('position', ''),
                    analysis_data.get('status', ''),
                    analysis_data.get('job_url', ''),
                    analysis_data.get('deadline', ''),
                    analysis_data.get('notes', ''),
                    analysis_data.get('confidence', 0),
                    analysis_data.get('analysis_method', ''),
                    ','.join(analysis_data.get('matched_keywords', [])),
                    datetime.now().isoformat()
                ])
        except Exception as e:
            logger.error(f"Error logging email analysis: {str(e)}")

    @staticmethod
    def _analyze_email_content(subject, body, from_email):
        """
        Enhanced email content analysis with strict validation
        Returns detailed analysis results with confidence scores
        """
        start_time = time.time()
        analysis_result = {
            'is_job_related': False,
            'company': 'Unknown Company',
            'position': 'Unknown Position',
            'status': 'Applied',
            'job_url': '',
            'deadline': None,
            'notes': '',
            'confidence': 0.0,
            'analysis_method': 'traditional',
            'matched_keywords': [],
            'analysis_time': 0,
            'validation_checks': []
        }

        # Combine text for analysis
        combined_text = (subject + " " + body).lower()
        
        # Validation checks
        validation_checks = []
        
        # 1. Check if it's a marketing email more aggressively
        marketing_indicators = [
            'unsubscribe', 'marketing', 'newsletter', 'promotion', 'special offer',
            'limited time', 'exclusive offer', 'deal', 'discount', 'sale',
            'sponsored', 'advertisement', 'advert', 'promotional', 'pricing',
            'buy now', 'shop now', 'order now', 'purchase now', 'promo code',
            'coupon', 'sale ends', 'clearance', 'new arrivals', 'best seller',
            'subscribe', 'subscription', 'membership', 'renew', 'upgrade'
        ]
        
        marketing_score = sum(2 for indicator in marketing_indicators if indicator in combined_text)
        
        # These phrases specifically indicate Tesla marketing emails
        tesla_marketing = [
            'tesla update', 'new tesla', 'test drive', 'tesla news', 'tesla inventory',
            'powertrain', 'model y', 'model 3', 'model s', 'model x', 'cybertruck', 
            'powerwall', 'solar roof', 'supercharger', 'autopark', 'autopilot', 'ownership',
            'charging', 'accessories', 'battery', 'sustainable energy'
        ]
        
        if 'tesla' in combined_text.lower():
            marketing_score += sum(3 for indicator in tesla_marketing if indicator in combined_text.lower())
        
        # Check for typical marketing email structure
        if 'view in browser' in combined_text or 'view as webpage' in combined_text:
            marketing_score += 2
            validation_checks.append('Marketing email structure detected')
        
        if marketing_score >= 4:
            validation_checks.append('Multiple marketing indicators detected')
            analysis_result['is_job_related'] = False
            analysis_result['confidence'] = 0.0
            analysis_result['notes'] = 'Marketing email detected'
            analysis_result['validation_checks'] = validation_checks
            analysis_result['analysis_time'] = time.time() - start_time
            return analysis_result
        
        # 2. Check for job board emails that aren't actually from employers
        job_board_domains = [
            'indeed', 'linkedin', 'ziprecruiter', 'glassdoor', 'monster', 
            'careerbuilder', 'dice', 'simplyhired', 'applytojob', 'lever', 
            'greenhouse', 'workday', 'taleo', 'jobvite', 'smartrecruiters',
            'recruiter', 'talent', 'jobsearch', 'careers', 'jobs'
        ]
        
        # Extract domain from from_email
        domain = ""
        domain_match = re.search(r'@([^.]+)', from_email)
        if domain_match:
            domain = domain_match.group(1).lower()
        
        is_job_board_email = any(board in domain for board in job_board_domains)
        
        # Check if it's a job alert but not an actual job application
        job_alert_indicators = ['job alert', 'jobs for you', 'recommended jobs', 'jobs you might like', 
                              'new jobs matching', 'job recommendations', 'search alert',
                              'your job matches', 'jobs in your area', 'top jobs']
        
        if is_job_board_email and any(indicator in combined_text for indicator in job_alert_indicators):
            if 'applied' not in combined_text and 'application' not in combined_text:
                validation_checks.append('Job board alert email detected')
                analysis_result['is_job_related'] = False
                analysis_result['confidence'] = 0.0
                analysis_result['notes'] = 'Job board alert email (not an application)'
                analysis_result['validation_checks'] = validation_checks
                analysis_result['analysis_time'] = time.time() - start_time
                return analysis_result
        
        # 3. Check for strong job-related indicators
        strong_matches = []
        for indicator in APPLICATION_KEYWORDS['strong_indicators']:
            if indicator.lower() in combined_text:
                strong_matches.append(indicator)
                analysis_result['matched_keywords'].append(indicator)
        
        if strong_matches:
            validation_checks.append(f'Strong job indicators found: {", ".join(strong_matches)}')
            analysis_result['is_job_related'] = True
            analysis_result['confidence'] = 0.9
        else:
            validation_checks.append('No strong job indicators found')
        
        # 4. Check for general indicators only if no strong indicators
        if not analysis_result['is_job_related']:
            general_matches = []
            for indicator in APPLICATION_KEYWORDS['general_indicators']:
                if indicator.lower() in combined_text:
                    general_matches.append(indicator)
                    analysis_result['matched_keywords'].append(indicator)
            
            if general_matches:
                validation_checks.append(f'General job indicators found: {", ".join(general_matches)}')
                # Require at least 2 general indicators for job-related classification
                if len(general_matches) >= 2:
                    analysis_result['is_job_related'] = True
                    analysis_result['confidence'] = 0.7
                else:
                    validation_checks.append('Insufficient general indicators')
            else:
                validation_checks.append('No general job indicators found')
        
        # 5. Extract and validate company name
        company_matches = []
        for pattern in COMPANY_PATTERNS:
            matches = re.findall(pattern, combined_text)
            company_matches.extend(matches)
        
        if company_matches:
            # Clean and validate company names
            valid_companies = []
            for company in company_matches:
                company = company.strip()
                if len(company) > 2 and not company.lower() in ['inc', 'llc', 'ltd', 'corp']:
                    valid_companies.append(company)
            
            if valid_companies:
                analysis_result['company'] = valid_companies[0]
                validation_checks.append(f'Company identified: {valid_companies[0]}')
            else:
                validation_checks.append('No valid company names found')
        else:
            validation_checks.append('No company names found')
        
        # 6. Extract and validate position
        position_matches = []
        for pattern in POSITION_PATTERNS:
            matches = re.findall(pattern, combined_text)
            position_matches.extend(matches)
        
        if position_matches:
            # Clean and validate position names
            valid_positions = []
            for position in position_matches:
                position = position.strip()
                if len(position) > 2:
                    valid_positions.append(position)
            
            if valid_positions:
                analysis_result['position'] = valid_positions[0]
                validation_checks.append(f'Position identified: {valid_positions[0]}')
            else:
                # Try additional position extraction methods
                subject_position = EmailService._extract_position_from_subject(subject)
                if subject_position != "Unknown Position":
                    analysis_result['position'] = subject_position
                    validation_checks.append(f'Position identified from subject: {subject_position}')
                else:
                    # Try extracting from the full content as last resort
                    content_position = EmailService._extract_position_from_email_content(subject, body)
                    if content_position != "Unknown Position":
                        analysis_result['position'] = content_position
                        validation_checks.append(f'Position identified from content: {content_position}')
                    else:
                        validation_checks.append('No position titles found')
        else:
            # Try additional position extraction methods
            subject_position = EmailService._extract_position_from_subject(subject)
            if subject_position != "Unknown Position":
                analysis_result['position'] = subject_position
                validation_checks.append(f'Position identified from subject: {subject_position}')
            else:
                # Try extracting from the full content as last resort
                content_position = EmailService._extract_position_from_email_content(subject, body)
                if content_position != "Unknown Position":
                    analysis_result['position'] = content_position
                    validation_checks.append(f'Position identified from content: {content_position}')
                else:
                    validation_checks.append('No position titles found')
        
        # 7. Determine application status
        status_scores = {
            'applied': 0,
            'in_progress': 0,
            'interview': 0,
            'rejected': 0,
            'offer': 0
        }
        
        # Weight factors for different parts of the email
        subject_weight = 2.0
        first_paragraph_weight = 1.5
        body_weight = 1.0
        
        # Break subject and body for contextual analysis
        subject_lower = subject.lower()
        body_lower = body.lower()
        
        # Get first paragraph for higher weighting
        first_paragraph = ""
        paragraphs = body_lower.split('\n\n')
        if paragraphs:
            first_paragraph = paragraphs[0].lower()
        
        # Score keywords by location and context
        for status, keywords in APPLICATION_KEYWORDS['status_indicators'].items():
            # Check subject with higher weight
            for keyword in keywords:
                keyword_lower = keyword.lower()
                # Check keyword in subject (highest weight)
                if keyword_lower in subject_lower:
                    status_scores[status] += subject_weight
                    validation_checks.append(f'Status indicator in subject: {keyword} ({status})')
                
                # Check keyword in first paragraph (higher weight)
                if keyword_lower in first_paragraph:
                    status_scores[status] += first_paragraph_weight
                    validation_checks.append(f'Status indicator in first paragraph: {keyword} ({status})')
                    
                # Check keyword in general body
                elif keyword_lower in body_lower:
                    status_scores[status] += body_weight
        
        # Context-aware status detection
        
        # Special cases that often indicate specific statuses
        # Rejection indicators often have specific phrases
        rejection_phrases = [
            "after careful consideration", 
            "we have decided not to proceed",
            "we regret to inform you",
            "we are unable to offer",
            "thank you for your interest, but",
            "we have filled the position",
            "we received many qualified applicants"
        ]
        
        for phrase in rejection_phrases:
            if phrase in combined_text:
                status_scores['rejected'] += 5  # High confidence override
                validation_checks.append(f'Strong rejection indicator: {phrase}')
        
        # Interview indicators
        interview_phrases = [
            "would like to schedule an interview",
            "invite you to interview",
            "schedule a time to meet",
            "next step in the process is an interview",
            "interview details below"
        ]
        
        for phrase in interview_phrases:
            if phrase in combined_text:
                status_scores['interview'] += 5  # High confidence override
                validation_checks.append(f'Strong interview indicator: {phrase}')
                
        # Offer indicators
        offer_phrases = [
            "pleased to offer you",
            "formal offer of employment",
            "welcome to the team",
            "offer details",
            "compensation package"
        ]
        
        for phrase in offer_phrases:
            if phrase in combined_text:
                status_scores['offer'] += 5  # High confidence override
                validation_checks.append(f'Strong offer indicator: {phrase}')
                
        # Log the scores for debugging
        for status, score in status_scores.items():
            if score > 0:
                validation_checks.append(f'Status score - {status}: {score}')
        
        # Get the status with the highest score
        if status_scores:
            max_status = max(status_scores.items(), key=lambda x: x[1])
            if max_status[1] > 0:
                # Map internal status to application status
                status_mapping = {
                    'applied': 'Applied',
                    'in_progress': 'In Progress',
                    'interview': 'Interview',
                    'rejected': 'Rejected',
                    'offer': 'Offer'
                }
                analysis_result['status'] = status_mapping.get(max_status[0], 'Applied')
                analysis_result['status_confidence'] = max_status[1] / 10.0 if max_status[1] < 10 else 1.0
                validation_checks.append(f'Selected status: {analysis_result["status"]} (confidence: {analysis_result["status_confidence"]:.2f})')
        
        # Add validation checks and analysis time to result
        analysis_result['validation_checks'] = validation_checks
        analysis_result['analysis_time'] = time.time() - start_time
        
        # Final confidence adjustment for job-related flag
        if analysis_result['is_job_related'] and is_job_board_email:
            # Be slightly less confident for job board emails unless they have strong indicators
            if analysis_result['confidence'] > 0.7 and not strong_matches:
                analysis_result['confidence'] -= 0.1
                
        # If both company and position are still unknown for a supposedly job-related email
        # it's likely not actually job-related
        if analysis_result['is_job_related'] and analysis_result['company'] == 'Unknown Company' and analysis_result['position'] == 'Unknown Position':
            if analysis_result['confidence'] < 0.9:  # Only adjust lower confidence matches
                analysis_result['is_job_related'] = False
                validation_checks.append('Downgraded to non-job-related: No company or position detected')
                analysis_result['notes'] = 'Suspected non-job email (no company/position detected)'
        
        return analysis_result
    
    @staticmethod
    def _scan_yahoo_imap(user):
        """
        Scan Yahoo Mail for job application emails with enhanced logging and validation
        """
        scan_id = str(int(time.time()))
        log_file = EmailService._create_analysis_log(user.id, scan_id)
        
        try:
            # Connect to Yahoo IMAP with retry logic
            max_retries = 3
            retry_count = 0
            imap = None
            
            while retry_count < max_retries:
                try:
                    # Create an SSL context with certificate verification and modern protocols
                    context = ssl.create_default_context()
                    context.options |= ssl.OP_NO_SSLv2 | ssl.OP_NO_SSLv3  # Disable older protocols
                    context.minimum_version = ssl.TLSVersion.TLSv1_2  # Require TLS 1.2 or higher
                    
                    imap = imaplib.IMAP4_SSL('imap.mail.yahoo.com', ssl_context=context)
                    imap.login(user.connected_email, user.email_password)
                    imap.select('INBOX')
                    break
                except (ssl.SSLError, imaplib.IMAP4.error) as e:
                    retry_count += 1
                    if retry_count == max_retries:
                        raise Exception(f"Failed to connect to Yahoo Mail after {max_retries} attempts: {str(e)}")
                    time.sleep(1)  # Wait before retrying
            
            # Get the last 100 emails
            _, message_numbers = imap.search(None, 'ALL')
            email_ids = message_numbers[0].split()
            total_emails = len(email_ids)
            
            # Process the last 100 emails
            emails_to_process = email_ids[-100:] if total_emails > 100 else email_ids
            logger.info(f"Processing {len(emails_to_process)} emails out of {total_emails} total emails")
            
            job_applications = []
            processed_count = 0
            marketing_emails = 0
            job_related_emails = 0
            
            for email_id in reversed(emails_to_process):
                try:
                    # Check if email is already processed
                    cached_data = EmailService._get_cached_email(email_id, user.id)
                    if cached_data:
                        processed_count += 1
                        if cached_data.get('is_job_related'):
                            job_applications.append(cached_data)
                            job_related_emails += 1
                        EmailService._log_email_analysis(log_file, cached_data)
                        continue
                    
                    # Fetch email
                    _, msg_data = imap.fetch(email_id, '(RFC822)')
                    email_body = msg_data[0][1]
                    email_message = email.message_from_bytes(email_body)
                    
                    # Extract email details
                    subject = email_message.get('subject', '')
                    from_email = email_message.get('from', '')
                    date_str = email_message.get('date', '')
                    
                    # Decode headers properly
                    if isinstance(subject, str):
                        subject = subject
                    else:
                        subject = str(subject)
                    
                    if isinstance(from_email, str):
                        from_email = from_email
                    else:
                        from_email = str(from_email)
                    
                    # Get email body
                    body = ""
                    if email_message.is_multipart():
                        for part in email_message.walk():
                            if part.get_content_type() == "text/plain":
                                try:
                                    body = part.get_payload(decode=True).decode('utf-8', errors='replace')
                                except:
                                    body = part.get_payload(decode=True).decode('latin1', errors='replace')
                    else:
                        try:
                            body = email_message.get_payload(decode=True).decode('utf-8', errors='replace')
                        except:
                            body = email_message.get_payload(decode=True).decode('latin1', errors='replace')
                    
                    # Analyze email content
                    analysis_result = EmailService._analyze_email_content(subject, body, from_email)
                    
                    # Add email metadata to analysis result
                    analysis_result.update({
                        'email_id': email_id.decode() if isinstance(email_id, bytes) else str(email_id),
                        'subject': subject,
                        'from_email': from_email,
                        'date': EmailService._parse_email_date(date_str)
                    })
                    
                    # Log analysis result
                    EmailService._log_email_analysis(log_file, analysis_result)
                    
                    # Update counters
                    if not analysis_result['is_job_related'] and any('Marketing email detected' in check for check in analysis_result.get('validation_checks', [])):
                        marketing_emails += 1
                    elif analysis_result['is_job_related']:
                        job_related_emails += 1
                        job_applications.append(analysis_result)
                        EmailService._cache_email(email_id, user.id, analysis_result)
                    
                    processed_count += 1
                    
                    # Log progress
                    if processed_count % 10 == 0:
                        logger.info(f"Processed {processed_count}/{len(emails_to_process)} emails. "
                                  f"Found {job_related_emails} job-related emails and {marketing_emails} marketing emails.")
                    
                except Exception as e:
                    logger.error(f"Error processing email {email_id}: {str(e)}")
                    continue
            
            # Log final results
            logger.info(f"Email scan completed:")
            logger.info(f"- Total emails processed: {processed_count}")
            logger.info(f"- Job-related emails: {job_related_emails}")
            logger.info(f"- Marketing emails: {marketing_emails}")
            logger.info(f"- Other emails: {processed_count - job_related_emails - marketing_emails}")
            
            imap.close()
            imap.logout()
            
            return {
                'success': True,
                'processed_count': processed_count,
                'total_count': len(emails_to_process),
                'job_applications': job_applications,
                'log_file': log_file,
                'stats': {
                    'job_related': job_related_emails,
                    'marketing': marketing_emails,
                    'other': processed_count - job_related_emails - marketing_emails
                }
            }
            
        except Exception as e:
            logger.error(f"Error in Yahoo IMAP scan: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'processed_count': processed_count,
                'total_count': len(emails_to_process) if 'emails_to_process' in locals() else 0,
                'job_applications': job_applications,
                'log_file': log_file
            }

    @staticmethod
    def _scan_gmail(user):
        """
        Scan Gmail for job application emails with enhanced logging
        """
        scan_id = str(int(time.time()))
        log_file = EmailService._create_analysis_log(user.id, scan_id)
        
        try:
            # Get credentials
            creds = EmailService._get_gmail_credentials(user)
            if not creds:
                return False, "Gmail credentials not found or expired. Please reconnect your Gmail account."
            
            # Build the Gmail API service
            service = build('gmail', 'v1', credentials=creds)
            
            # Get messages from the last day only (for testing purposes)
            one_day_ago = (datetime.now() - timedelta(days=1)).strftime('%Y/%m/%d')
            query = f'after:{one_day_ago}'
            
            # Execute the API request
            results = service.users().messages().list(userId='me', q=query, maxResults=10).execute()
            messages = results.get('messages', [])
            
            if not messages:
                return True, []  # No emails found
            
            job_applications = []
            processed_count = 0
            
            # Process each message
            for message in messages:
                try:
                    msg = service.users().messages().get(userId='me', id=message['id'], format='full').execute()
                    
                    # Extract headers
                    headers = msg['payload']['headers']
                    subject = next((h['value'] for h in headers if h['name'].lower() == 'subject'), 'No Subject')
                    from_email = next((h['value'] for h in headers if h['name'].lower() == 'from'), 'Unknown Sender')
                    date_str = next((h['value'] for h in headers if h['name'].lower() == 'date'), None)
                    
                    # Parse date
                    email_date = EmailService._parse_email_date(date_str) if date_str else datetime.now()
                    
                    # Extract body
                    body = EmailService._get_email_body(msg['payload'])
                    
                    # Analyze email content
                    analysis_result = EmailService._analyze_email_content(subject, body, from_email)
                    
                    # Add email metadata to analysis result
                    analysis_result.update({
                        'email_id': message['id'],
                        'subject': subject,
                        'from_email': from_email,
                        'date': email_date
                    })
                    
                    # Log analysis result
                    EmailService._log_email_analysis(log_file, analysis_result)
                    
                    # If job-related, add to list
                    if analysis_result['is_job_related']:
                        job_applications.append(analysis_result)
                    
                    processed_count += 1
                    
                except Exception as e:
                    logger.error(f"Error processing Gmail message {message['id']}: {str(e)}")
                    continue
            
            return {
                'success': True,
                'processed_count': processed_count,
                'total_count': len(messages),
                'job_applications': job_applications,
                'log_file': log_file
            }
            
        except Exception as e:
            logger.error(f"Error scanning Gmail for user {user.id}: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'processed_count': 0,
                'total_count': 0,
                'job_applications': [],
                'log_file': log_file
            }

    @staticmethod
    def _review_scan_results(log_file):
        """
        Review the scan results and analyze accuracy
        """
        try:
            with open(log_file, 'r') as f:
                reader = csv.DictReader(f)
                results = list(reader)
            
            total_emails = len(results)
            job_related = sum(1 for r in results if r['Is Job Related'].lower() == 'true')
            high_confidence = sum(1 for r in results if float(r['Confidence']) >= 0.8)
            
            # Calculate accuracy metrics
            metrics = {
                'total_emails': total_emails,
                'job_related_count': job_related,
                'high_confidence_count': high_confidence,
                'job_related_percentage': (job_related / total_emails * 100) if total_emails > 0 else 0,
                'high_confidence_percentage': (high_confidence / total_emails * 100) if total_emails > 0 else 0
            }
            
            # Log review results
            logger.info(f"Scan Results Review for {log_file}:")
            logger.info(f"Total emails processed: {metrics['total_emails']}")
            logger.info(f"Job-related emails: {metrics['job_related_count']} ({metrics['job_related_percentage']:.1f}%)")
            logger.info(f"High confidence results: {metrics['high_confidence_count']} ({metrics['high_confidence_percentage']:.1f}%)")
            
            # Analyze patterns and keywords
            if total_emails > 0:
                # Collect all matched keywords
                all_keywords = []
                for result in results:
                    keywords = result['Matched Keywords'].split(',')
                    all_keywords.extend([k.strip() for k in keywords if k.strip()])
                
                # Count keyword frequencies
                keyword_freq = {}
                for keyword in all_keywords:
                    keyword_freq[keyword] = keyword_freq.get(keyword, 0) + 1
                
                # Sort keywords by frequency
                sorted_keywords = sorted(keyword_freq.items(), key=lambda x: x[1], reverse=True)
                
                # Log keyword analysis
                logger.info("\nKeyword Analysis:")
                for keyword, freq in sorted_keywords[:20]:  # Top 20 keywords
                    percentage = (freq / total_emails) * 100
                    logger.info(f"{keyword}: {freq} occurrences ({percentage:.1f}%)")
                
                # Analyze false positives and negatives
                false_positives = []
                false_negatives = []
                
                for result in results:
                    if result['Is Job Related'].lower() == 'true' and float(result['Confidence']) < 0.5:
                        false_positives.append({
                            'subject': result['Subject'],
                            'from': result['From'],
                            'confidence': result['Confidence']
                        })
                    elif result['Is Job Related'].lower() == 'false' and float(result['Confidence']) > 0.7:
                        false_negatives.append({
                            'subject': result['Subject'],
                            'from': result['From'],
                            'confidence': result['Confidence']
                        })
                
                if false_positives:
                    logger.info("\nPotential False Positives:")
                    for fp in false_positives[:5]:  # Top 5 false positives
                        logger.info(f"Subject: {fp['subject']}")
                        logger.info(f"From: {fp['from']}")
                        logger.info(f"Confidence: {fp['confidence']}")
                
                if false_negatives:
                    logger.info("\nPotential False Negatives:")
                    for fn in false_negatives[:5]:  # Top 5 false negatives
                        logger.info(f"Subject: {fn['subject']}")
                        logger.info(f"From: {fn['from']}")
                        logger.info(f"Confidence: {fn['confidence']}")
            
            return metrics
            
        except Exception as e:
            logger.error(f"Error reviewing scan results: {str(e)}")
            return None

    @staticmethod
    def analyze_log_files():
        """
        Analyze all log files in the analysis directory to identify patterns
        and suggest improvements to the analysis system.
        """
        try:
            analysis_dir = Path('job_app_tracker/logs/analysis')
            if not analysis_dir.exists():
                logger.warning("Analysis directory not found")
                return
            
            # Get all CSV files
            log_files = list(analysis_dir.glob('*.csv'))
            if not log_files:
                logger.warning("No log files found")
                return
            
            # Collect data from all files
            all_results = []
            for log_file in log_files:
                try:
                    with open(log_file, 'r') as f:
                        reader = csv.DictReader(f)
                        all_results.extend(list(reader))
                except Exception as e:
                    logger.error(f"Error reading log file {log_file}: {str(e)}")
                    continue
            
            if not all_results:
                logger.warning("No results found in log files")
                return
            
            # Analyze patterns
            total_emails = len(all_results)
            job_related = sum(1 for r in all_results if r['Is Job Related'].lower() == 'true')
            high_confidence = sum(1 for r in all_results if float(r['Confidence']) >= 0.8)
            
            # Calculate overall metrics
            metrics = {
                'total_emails': total_emails,
                'job_related_count': job_related,
                'high_confidence_count': high_confidence,
                'job_related_percentage': (job_related / total_emails * 100) if total_emails > 0 else 0,
                'high_confidence_percentage': (high_confidence / total_emails * 100) if total_emails > 0 else 0
            }
            
            # Log overall analysis
            logger.info("\nOverall Analysis Results:")
            logger.info(f"Total emails analyzed: {metrics['total_emails']}")
            logger.info(f"Job-related emails: {metrics['job_related_count']} ({metrics['job_related_percentage']:.1f}%)")
            logger.info(f"High confidence results: {metrics['high_confidence_count']} ({metrics['high_confidence_percentage']:.1f}%)")
            
            # Analyze company patterns
            company_patterns = {}
            for result in all_results:
                company = result['Company']
                if company and company != 'Unknown Company':
                    company_patterns[company] = company_patterns.get(company, 0) + 1
            
            # Log company patterns
            if company_patterns:
                logger.info("\nCompany Patterns:")
                sorted_companies = sorted(company_patterns.items(), key=lambda x: x[1], reverse=True)
                for company, count in sorted_companies[:10]:  # Top 10 companies
                    percentage = (count / total_emails) * 100
                    logger.info(f"{company}: {count} occurrences ({percentage:.1f}%)")
            
            # Analyze position patterns
            position_patterns = {}
            for result in all_results:
                position = result['Position']
                if position and position != 'Unknown Position':
                    position_patterns[position] = position_patterns.get(position, 0) + 1
            
            # Log position patterns
            if position_patterns:
                logger.info("\nPosition Patterns:")
                sorted_positions = sorted(position_patterns.items(), key=lambda x: x[1], reverse=True)
                for position, count in sorted_positions[:10]:  # Top 10 positions
                    percentage = (count / total_emails) * 100
                    logger.info(f"{position}: {count} occurrences ({percentage:.1f}%)")
            
            # Analyze status patterns
            status_patterns = {}
            for result in all_results:
                status = result['Status']
                if status:
                    status_patterns[status] = status_patterns.get(status, 0) + 1
            
            # Log status patterns
            if status_patterns:
                logger.info("\nStatus Patterns:")
                sorted_statuses = sorted(status_patterns.items(), key=lambda x: x[1], reverse=True)
                for status, count in sorted_statuses:
                    percentage = (count / total_emails) * 100
                    logger.info(f"{status}: {count} occurrences ({percentage:.1f}%)")
            
            # Suggest improvements
            logger.info("\nSuggested Improvements:")
            
            # Check keyword effectiveness
            all_keywords = []
            for result in all_results:
                keywords = result['Matched Keywords'].split(',')
                all_keywords.extend([k.strip() for k in keywords if k.strip()])
            
            keyword_freq = {}
            for keyword in all_keywords:
                keyword_freq[keyword] = keyword_freq.get(keyword, 0) + 1
            
            # Find potentially missing keywords
            high_confidence_jobs = [r for r in all_results if r['Is Job Related'].lower() == 'true' and float(r['Confidence']) >= 0.8]
            if high_confidence_jobs:
                logger.info("\nHigh Confidence Job Emails without Strong Keywords:")
                for result in high_confidence_jobs[:5]:
                    logger.info(f"Subject: {result['Subject']}")
                    logger.info(f"From: {result['From']}")
                    logger.info(f"Confidence: {result['Confidence']}")
            
            # Check for patterns in false positives
            false_positives = [r for r in all_results if r['Is Job Related'].lower() == 'true' and float(r['Confidence']) < 0.5]
            if false_positives:
                logger.info("\nPatterns in False Positives:")
                for result in false_positives[:5]:
                    logger.info(f"Subject: {result['Subject']}")
                    logger.info(f"From: {result['From']}")
                    logger.info(f"Confidence: {result['Confidence']}")
            
            return metrics
            
        except Exception as e:
            logger.error(f"Error analyzing log files: {str(e)}")
            return None

    @staticmethod
    def _get_cached_email(email_id, user_id):
        """Get cached email analysis result"""
        try:
            cache_key = f"{user_id}_{email_id}"
            cached_data = EmailService._analysis_cache.get(cache_key)
            if cached_data:
                return cached_data
            return None
        except Exception as e:
            logger.error(f"Error getting cached email: {str(e)}")
            return None

    @staticmethod
    def _cache_email(email_id, user_id, analysis_data):
        """Cache email analysis result"""
        try:
            cache_key = f"{user_id}_{email_id}"
            EmailService._analysis_cache[cache_key] = analysis_data
        except Exception as e:
            logger.error(f"Error caching email: {str(e)}")

    @staticmethod
    def _clear_cache():
        """Clear all caches"""
        try:
            EmailService._cache.clear()
            EmailService._email_cache.clear()
            EmailService._analysis_cache.clear()
            logger.info("Cache cleared successfully")
        except Exception as e:
            logger.error(f"Error clearing cache: {str(e)}")

    @staticmethod
    def _cleanup_expired_cache():
        """Clean up expired cache entries"""
        try:
            current_time = time.time()
            # Clean up email cache
            EmailService._email_cache = {
                k: v for k, v in EmailService._email_cache.items()
                if current_time - v.get('timestamp', 0) < EmailService._email_cache_ttl
            }
            # Clean up analysis cache
            EmailService._analysis_cache = {
                k: v for k, v in EmailService._analysis_cache.items()
                if current_time - v.get('timestamp', 0) < EmailService._cache_ttl
            }
        except Exception as e:
            logger.error(f"Error cleaning up cache: {str(e)}")

    @staticmethod
    def get_gmail_auth_url(user_id):
        """Generate Gmail OAuth URL"""
        client_config = {
            "web": {
                "client_id": os.environ.get("GOOGLE_CLIENT_ID"),
                "client_secret": os.environ.get("GOOGLE_CLIENT_SECRET"),
                "auth_uri": "https://accounts.google.com/o/oauth2/auth",
                "token_uri": "https://oauth2.googleapis.com/token",
                "redirect_uris": [os.environ.get("GOOGLE_REDIRECT_URI")]
            }
        }
        
        flow = Flow.from_client_config(
            client_config,
            scopes=GMAIL_SCOPES,
            redirect_uri=os.environ.get("GOOGLE_REDIRECT_URI")
        )
        
        # Store state in session or database
        state = base64.urlsafe_b64encode(user_id.encode()).decode()
        auth_url, _ = flow.authorization_url(
            access_type='offline',
            include_granted_scopes='true',
            state=state,
            prompt='consent'
        )
        
        return auth_url
    
    @staticmethod
    def handle_gmail_callback(code, state):
        """Handle Gmail OAuth callback"""
        # Decode user_id from state
        user_id = base64.urlsafe_b64decode(state.encode()).decode()
        
        client_config = {
            "web": {
                "client_id": os.environ.get("GOOGLE_CLIENT_ID"),
                "client_secret": os.environ.get("GOOGLE_CLIENT_SECRET"),
                "auth_uri": "https://accounts.google.com/o/oauth2/auth",
                "token_uri": "https://oauth2.googleapis.com/token",
                "redirect_uris": [os.environ.get("GOOGLE_REDIRECT_URI")]
            }
        }
        
        flow = Flow.from_client_config(
            client_config,
            scopes=GMAIL_SCOPES,
            redirect_uri=os.environ.get("GOOGLE_REDIRECT_URI")
        )
        
        # Exchange code for tokens
        flow.fetch_token(code=code)
        credentials = flow.credentials
        
        # Get user email
        service = build('gmail', 'v1', credentials=credentials)
        profile = service.users().getProfile(userId='me').execute()
        email = profile['emailAddress']
        
        # Store tokens in database
        from job_app_tracker.models.user import User
        user = User.get_by_id(user_id)
        if user:
            expiry = datetime.utcnow() + timedelta(seconds=credentials.expiry)
            user.update_email_connection(
                connected_email=email,
                provider='gmail',
                token=credentials.token,
                refresh_token=credentials.refresh_token,
                expiry=expiry
            )
            return True, user
        
        return False, None
    
    @staticmethod
    def connect_yahoo_imap(user_id, yahoo_email, app_password):
        """Connect to Yahoo Mail using IMAP with app password"""
        try:
            # Create an SSL context with certificate verification and modern protocols
            context = ssl.create_default_context()
            context.options |= ssl.OP_NO_SSLv2 | ssl.OP_NO_SSLv3  # Disable older protocols
            context.minimum_version = ssl.TLSVersion.TLSv1_2  # Require TLS 1.2 or higher
            
            # Test connection
            imap = imaplib.IMAP4_SSL('imap.mail.yahoo.com', ssl_context=context)
            imap.login(yahoo_email, app_password)
            imap.select('INBOX')
            imap.close()
            imap.logout()
            
            # Get user
            user = User.get_by_id(user_id)
            if not user:
                return False, "User not found"
            
            # Update user's email connection
            update_data = {
                'email_connected': True,
                'connected_email': yahoo_email,
                'email_provider': 'yahoo',
                'email_password': app_password,
                'email_settings': {
                    'auto_scan': True,
                    'require_approval': True,
                    'scan_attachments': False,
                    'last_scan': None
                }
            }
            
            mongo.db.users.update_one(
                {'_id': ObjectId(user_id)},
                {'$set': update_data}
            )
            
            return True, "Successfully connected to Yahoo Mail"
            
        except imaplib.IMAP4.error as e:
            logger.error(f"IMAP error: {str(e)}")
            return False, f"Failed to connect to Yahoo Mail: {str(e)}"
        except Exception as e:
            logger.error(f"Error connecting to Yahoo Mail: {str(e)}")
            return False, f"Failed to connect to Yahoo Mail: {str(e)}"
    
    @staticmethod
    def scan_emails(user):
        """
        Scan user's emails for job applications
        Returns a tuple of (success, message, redirect_url)
        """
        # Check if email is connected
        if not user.email_connected:
            return False, "Email not connected. Please connect an email account first.", "main.settings"
        
        # Check if user is premium - PREMIUM ONLY FEATURE
        if not user.is_premium:
            return False, "Email scanning is a premium feature. Please upgrade to premium.", "main.settings"
        
        # Check if email provider is specified
        if not hasattr(user, 'email_provider') or not user.email_provider:
            return False, "Email provider not specified. Please reconnect your email account.", "main.settings"
        
        # Check if we've scanned recently (within the last minute for testing purposes)
        if hasattr(user, 'email_settings') and user.email_settings and user.email_settings.get('last_scan'):
            last_scan = user.email_settings.get('last_scan')
            if isinstance(last_scan, str):
                try:
                    last_scan = datetime.fromisoformat(last_scan)
                except ValueError:
                    last_scan = None
            
            if last_scan and (datetime.now() - last_scan).total_seconds() < 60:
                return False, "Emails were scanned recently. Please try again in a minute.", "main.email_suggestions"
        
        # Determine which email provider to use and scan accordingly
        if user.email_provider == 'gmail':
            logger.info(f"Scanning Gmail for user {user.id}")
            success, job_applications = EmailService._scan_gmail(user)
        elif user.email_provider == 'yahoo_imap':
            logger.info(f"Scanning Yahoo Mail for user {user.id}")
            result = EmailService._scan_yahoo_imap(user)
            success = result.get('success', False)
            if success:
                job_applications = result.get('job_applications', [])
                # Update last scan time
                user.last_email_scan = datetime.utcnow()
                user.save()
            else:
                return False, result.get('message', 'Error scanning Yahoo Mail'), "main.email_suggestions"
        elif user.email_provider == 'outlook':
            logger.info(f"Scanning Outlook for user {user.id}")
            success, job_applications = EmailService._scan_outlook(user)
        else:
            logger.error(f"Unsupported email provider: {user.email_provider}")
            return False, f"Unsupported email provider: {user.email_provider}. Please reconnect with Gmail, Yahoo, or Outlook.", "main.settings"
        
        if not success:
            logger.error(f"Email scan failed: {job_applications}")
            return False, job_applications, "main.email_suggestions"  # In this case, job_applications contains the error message
        
        # Update last scan time
        if hasattr(user, 'email_settings') and user.email_settings:
            email_settings = user.email_settings.copy()
        else:
            email_settings = {}
        
        email_settings['last_scan'] = datetime.now()
        
        # Update user settings
        mongo.db.users.update_one(
            {'_id': ObjectId(user.id)},
            {'$set': {'email_settings': email_settings}}
        )
        
        # Process applications
        if job_applications:
            suggestions_count = EmailService._process_applications(user, job_applications)
            logger.info(f"Found {len(job_applications)} job application emails, created {suggestions_count} suggestions")
            return True, f"Found {len(job_applications)} potential job application emails", "main.email_suggestions"
        else:
            logger.info(f"No job application emails found for user {user.id}")
            return True, "No job application emails found", "main.email_suggestions"
    
    @staticmethod
    def _get_gmail_credentials(user):
        """
        Get Gmail credentials for the user
        Returns a Credentials object or None if credentials are invalid
        """
        try:
            # Check if user has Gmail credentials
            if not hasattr(user, 'email_token') or not user.email_token:
                logger.error(f"User {user.id} has no Gmail token")
                return None
                
            if not hasattr(user, 'email_refresh_token') or not user.email_refresh_token:
                logger.error(f"User {user.id} has no Gmail refresh token")
                return None
            
            # Create credentials object
            credentials = Credentials(
                token=user.email_token,
                refresh_token=user.email_refresh_token,
                token_uri="https://oauth2.googleapis.com/token",
                client_id=os.environ.get("GOOGLE_CLIENT_ID"),
                client_secret=os.environ.get("GOOGLE_CLIENT_SECRET"),
                scopes=GMAIL_SCOPES
            )
            
            # Check if token is expired and refresh if needed
            if hasattr(user, 'email_token_expiry') and user.email_token_expiry:
                if isinstance(user.email_token_expiry, str):
                    try:
                        expiry = datetime.fromisoformat(user.email_token_expiry)
                    except ValueError:
                        expiry = None
                else:
                    expiry = user.email_token_expiry
                
                if expiry and expiry < datetime.utcnow():
                    logger.info(f"Refreshing expired Gmail token for user {user.id}")
                    credentials.refresh(requests.Request())
                    
                    # Update tokens in database
                    mongo.db.users.update_one(
                        {'_id': ObjectId(user.id)},
                        {'$set': {
                            'email_token': credentials.token,
                            'email_refresh_token': credentials.refresh_token,
                            'email_token_expiry': datetime.utcnow() + timedelta(seconds=credentials.expiry)
                        }}
                    )
            
            return credentials
            
        except Exception as e:
            logger.error(f"Error getting Gmail credentials for user {user.id}: {str(e)}")
            return None

    @staticmethod
    def _scan_outlook(user):
        """Scan Outlook for job applications"""
        # Implementation for Outlook would go here
        return False, "Outlook integration not implemented yet"
    
    @staticmethod
    def _get_email_body(payload):
        """Extract email body from payload"""
        body = ""
        
        if 'body' in payload and payload['body'].get('data'):
            body = base64.urlsafe_b64decode(payload['body']['data']).decode('utf-8')
        elif 'parts' in payload:
            for part in payload['parts']:
                if part['mimeType'] == 'text/plain' and 'data' in part['body']:
                    body = base64.urlsafe_b64decode(part['body']['data']).decode('utf-8')
                    break
                elif part['mimeType'] == 'text/html' and 'data' in part['body']:
                    html = base64.urlsafe_b64decode(part['body']['data']).decode('utf-8')
                    soup = BeautifulSoup(html, 'html.parser')
                    body = soup.get_text()
                    break
                elif 'parts' in part:
                    # Recursive call for multipart emails
                    body = EmailService._get_email_body(part)
                    if body:
                        break
        
        return body
    
    @staticmethod
    def _is_job_related(subject, body):
        """
        Check if email is job-related using enhanced keyword detection
        This is a FALLBACK method for premium users when AI analysis fails
        """
        combined_text = (subject + " " + body).lower()
        
        # Check for job-related keywords
        keyword_count = 0
        matched_keywords = []
        
        for keyword in APPLICATION_KEYWORDS['general_indicators']:
            if keyword.lower() in combined_text:
                keyword_count += 1
                matched_keywords.append(keyword)
                
                # If we find a strong indicator phrase (multi-word), give it more weight
                if len(keyword.split()) > 1:
                    keyword_count += 1
        
        # Check for status-specific keywords which also indicate job-relatedness
        for status, keywords in APPLICATION_KEYWORDS['status_indicators'].items():
            for keyword in keywords:
                if keyword.lower() in combined_text and keyword not in matched_keywords:
                    keyword_count += 1
                    matched_keywords.append(keyword)
                    
                    # If we find a strong indicator phrase (multi-word), give it more weight
                    if len(keyword.split()) > 1:
                        keyword_count += 0.5
        
        # Log the matched keywords for debugging
        if keyword_count > 0:
            logger.debug(f"Job-related keywords found: {matched_keywords}")
        
        # If multiple keywords found, likely job-related
        # Higher threshold for single-word matches, lower for multi-word phrases
        return keyword_count >= 2
    
    @staticmethod
    def _extract_company(from_email, subject, body):
        """Extract company name from email"""
        # Try to extract from email domain
        domain_match = re.search(r'@([^.]+)', from_email)
        domain_company = None
        
        if domain_match:
            domain = domain_match.group(1)
            # Skip common email providers
            common_email_providers = [
                'gmail', 'yahoo', 'hotmail', 'outlook', 'aol', 'icloud', 
                'protonmail', 'mail', 'me', 'live', 'msn', 'ymail', 'inbox'
            ]
            if domain.lower() not in common_email_providers:
                domain_company = domain.title()
        
        # Try to extract from signature or common patterns
        combined_text = subject + "\n" + body
        
        # Check for company names using patterns
        for pattern in COMPANY_PATTERNS:
            match = re.search(pattern, combined_text)
            if match:
                company_name = match.group(1).strip()
                # Basic validation - must be at least 2 characters and not just common words
                common_words = ['team', 'hiring', 'recruiter', 'talent', 'acquisition', 'job', 'application']
                if (len(company_name) >= 2 and 
                    company_name.lower() not in common_words and
                    not company_name.isdigit()):
                    return company_name
        
        # If we found a domain-based company name earlier, use that
        if domain_company:
            return domain_company
        
        # Check for sender name as potential company
        sender_match = re.search(r'^([^<]+)', from_email)
        if sender_match:
            sender_name = sender_match.group(1).strip()
            # If sender name looks like a company (contains multiple words or capital letters)
            words = sender_name.split()
            if len(words) > 1 and any(word[0].isupper() for word in words):
                return sender_name
        
        # Extract domain company name from email more aggressively
        email_parts = from_email.split('@')
        if len(email_parts) > 1:
            domain_parts = email_parts[1].split('.')
            if len(domain_parts) > 0:
                # Try domain without TLD
                domain = domain_parts[0]
                if domain.lower() not in common_email_providers:
                    return domain.title()
        
        return "Unknown Company"
    
    @staticmethod
    def _extract_position(subject, body):
        """
        Extract job position from email subject and body
        """
        try:
            # First try to extract from subject
            subject_patterns = [
                r'(?:position|role|job|opportunity)(?:\s+for)?\s+(?:of\s+)?([A-Za-z0-9\s]+(?:Developer|Engineer|Manager|Designer|Analyst|Specialist|Director|Coordinator|Assistant|Administrator|Consultant|Architect|Lead|Senior|Junior|Principal|Staff|Head|Chief|Officer|President|Vice President|VP|CEO|CTO|CFO|COO|CIO|Founder|Co-founder|Partner|Associate|Intern|Trainee|Apprentice))',
                r'([A-Za-z0-9\s]+(?:Developer|Engineer|Manager|Designer|Analyst|Specialist|Director|Coordinator|Assistant|Administrator|Consultant|Architect|Lead|Senior|Junior|Principal|Staff|Head|Chief|Officer|President|Vice President|VP|CEO|CTO|CFO|COO|CIO|Founder|Co-founder|Partner|Associate|Intern|Trainee|Apprentice))\s+(?:position|role|job|opportunity)',
                r'(?:applying|application|candidacy)\s+for\s+([A-Za-z0-9\s]+)',
                r'(?:looking for|seeking|hiring)\s+([A-Za-z0-9\s]+)',
                r'([A-Za-z0-9\s]+(?:Developer|Engineer|Manager|Designer|Analyst|Specialist|Director|Coordinator|Assistant|Administrator|Consultant|Architect|Lead|Senior|Junior|Principal|Staff|Head|Chief|Officer|President|Vice President|VP|CEO|CTO|CFO|COO|CIO|Founder|Co-founder|Partner|Associate|Intern|Trainee|Apprentice))(?:\s+at|\s+with|\s+for)?\s+[A-Za-z0-9\s]+',
                r'[A-Za-z0-9\s]+(?:\s+at|\s+with|\s+for)?\s+([A-Za-z0-9\s]+(?:Developer|Engineer|Manager|Designer|Analyst|Specialist|Director|Coordinator|Assistant|Administrator|Consultant|Architect|Lead|Senior|Junior|Principal|Staff|Head|Chief|Officer|President|Vice President|VP|CEO|CTO|CFO|COO|CIO|Founder|Co-founder|Partner|Associate|Intern|Trainee|Apprentice))'
            ]
            
            for pattern in subject_patterns:
                match = re.search(pattern, subject)
                if match:
                    position = match.group(1).strip()
                    if position and position.lower() not in ['details', 'terms', 'conditions', 'privacy', 'policy', 'updates']:
                        logger.info(f"Extracted position from subject: {position}")
                        return position
            
            # If not found in subject, try body
            body_patterns = [
                r'(?:position|role|job|opportunity)(?:\s+for)?\s+(?:of\s+)?([A-Za-z0-9\s]+(?:Developer|Engineer|Manager|Designer|Analyst|Specialist|Director|Coordinator|Assistant|Administrator|Consultant|Architect|Lead|Senior|Junior|Principal|Staff|Head|Chief|Officer|President|Vice President|VP|CEO|CTO|CFO|COO|CIO|Founder|Co-founder|Partner|Associate|Intern|Trainee|Apprentice))',
                r'([A-Za-z0-9\s]+(?:Developer|Engineer|Manager|Designer|Analyst|Specialist|Director|Coordinator|Assistant|Administrator|Consultant|Architect|Lead|Senior|Junior|Principal|Staff|Head|Chief|Officer|President|Vice President|VP|CEO|CTO|CFO|COO|CIO|Founder|Co-founder|Partner|Associate|Intern|Trainee|Apprentice))\s+(?:position|role|job|opportunity)',
                r'(?:applying|application|candidacy)\s+for\s+([A-Za-z0-9\s]+)',
                r'(?:looking for|seeking|hiring)\s+([A-Za-z0-9\s]+)',
                r'([A-Za-z0-9\s]+(?:Developer|Engineer|Manager|Designer|Analyst|Specialist|Director|Coordinator|Assistant|Administrator|Consultant|Architect|Lead|Senior|Junior|Principal|Staff|Head|Chief|Officer|President|Vice President|VP|CEO|CTO|CFO|COO|CIO|Founder|Co-founder|Partner|Associate|Intern|Trainee|Apprentice))(?:\s+at|\s+with|\s+for)?\s+[A-Za-z0-9\s]+',
                r'[A-Za-z0-9\s]+(?:\s+at|\s+with|\s+for)?\s+([A-Za-z0-9\s]+(?:Developer|Engineer|Manager|Designer|Analyst|Specialist|Director|Coordinator|Assistant|Administrator|Consultant|Architect|Lead|Senior|Junior|Principal|Staff|Head|Chief|Officer|President|Vice President|VP|CEO|CTO|CFO|COO|CIO|Founder|Co-founder|Partner|Associate|Intern|Trainee|Apprentice))'
            ]
            
            for pattern in body_patterns:
                match = re.search(pattern, body)
                if match:
                    position = match.group(1).strip()
                    if position and position.lower() not in ['details', 'terms', 'conditions', 'privacy', 'policy', 'updates']:
                        logger.info(f"Extracted position from body: {position}")
                        return position
            
            # If still not found, try to extract from company name in subject
            company_pattern = r'([A-Za-z0-9\s]+(?:\s+at|\s+with|\s+for)?\s+[A-Za-z0-9\s]+(?:Developer|Engineer|Manager|Designer|Analyst|Specialist|Director|Coordinator|Assistant|Administrator|Consultant|Architect|Lead|Senior|Junior|Principal|Staff|Head|Chief|Officer|President|Vice President|VP|CEO|CTO|CFO|COO|CIO|Founder|Co-founder|Partner|Associate|Intern|Trainee|Apprentice))'
            match = re.search(company_pattern, subject)
            if match:
                position = match.group(1).strip()
                if position and position.lower() not in ['details', 'terms', 'conditions', 'privacy', 'policy', 'updates']:
                    logger.info(f"Extracted position from company name in subject: {position}")
                    return position
            
            logger.info("No position found in email")
            return "Not specified"
            
        except Exception as e:
            logger.error(f"Error extracting position: {str(e)}")
            return "Not specified"

    @staticmethod
    def _extract_job_url(subject, body):
        """
        Extract job posting URL from email subject and body
        """
        try:
            # Common URL patterns in job-related emails
            url_patterns = [
                r'https?://(?:www\.)?(?:linkedin\.com|indeed\.com|glassdoor\.com|monster\.com|careerbuilder\.com|ziprecruiter\.com|dice\.com|hired\.com|angellist\.com|wellfound\.com|lever\.co|greenhouse\.io|workday\.com|jobvite\.com|smartrecruiters\.com|taleo\.net|applicanttracking\.com|recruiter\.com|talent\.com|hiring\.com|careers\.com|jobs\.com|employment\.com|staffing\.com|headhunter\.com)/[^\s<>"]+',
                r'https?://(?:www\.)?[^\s<>"]+\.(?:com|org|net|io|co|ai|dev)/[^\s<>"]+',
                r'https?://[^\s<>"]+'
            ]
            
            # First try to find URLs in the subject
            for pattern in url_patterns:
                matches = re.findall(pattern, subject)
                if matches:
                    # Filter out common non-job URLs
                    for url in matches:
                        if not any(x in url.lower() for x in ['unsubscribe', 'update', 'preferences', 'settings', 'profile', 'terms', 'privacy', 'policy']):
                            logger.info(f"Found job URL in subject: {url}")
                            return url
            
            # If not found in subject, try body
            for pattern in url_patterns:
                matches = re.findall(pattern, body)
                if matches:
                    # Filter out common non-job URLs
                    for url in matches:
                        if not any(x in url.lower() for x in ['unsubscribe', 'update', 'preferences', 'settings', 'profile', 'terms', 'privacy', 'policy']):
                            logger.info(f"Found job URL in body: {url}")
                            return url
            
            logger.info("No job URL found in email")
            return "https://example.com/job-posting"  # Default URL
            
        except Exception as e:
            logger.error(f"Error extracting job URL: {str(e)}")
            return "https://example.com/job-posting"  # Default URL
    
    @staticmethod
    def _determine_status(subject, body):
        """
        Determine application status from email content with enhanced keyword detection
        """
        combined_text = (subject + " " + body).lower()
        
        # Check for each status type
        status_scores = {}
        
        for status, keywords in APPLICATION_KEYWORDS['status_indicators'].items():
            # Count keyword matches
            base_score = sum(1 for keyword in keywords if keyword.lower() in combined_text)
            
            # Give extra weight to multi-word phrases as they're more specific
            phrase_bonus = sum(0.5 for keyword in keywords 
                              if len(keyword.split()) > 1 and keyword.lower() in combined_text)
            
            status_scores[status] = base_score + phrase_bonus
        
        # Get status with highest score
        if status_scores:
            max_status = max(status_scores.items(), key=lambda x: x[1])
            if max_status[1] > 0:
                # Map internal status to application status
                status_mapping = {
                    'applied': 'Applied',
                    'in_progress': 'In Progress',
                    'interview': 'Interview',
                    'rejected': 'Rejected',
                    'offer': 'Offer'
                }
                return status_mapping.get(max_status[0], 'Applied')
        
        # Default to Applied if no clear status
        return 'Applied'
    
    @staticmethod
    def _parse_email_date(date_str):
        """Parse email date string to datetime"""
        try:
            # Handle various date formats
            formats = [
                '%a, %d %b %Y %H:%M:%S %z',
                '%d %b %Y %H:%M:%S %z',
                '%a, %d %b %Y %H:%M:%S',
                '%d %b %Y %H:%M:%S'
            ]
            
            for fmt in formats:
                try:
                    return datetime.strptime(date_str, fmt)
                except ValueError:
                    continue
            
            # Default to current time if parsing fails
            return datetime.utcnow()
        except:
            return datetime.utcnow()

    @staticmethod
    def _process_applications(user, job_applications):
        """
        Process job applications found in emails
        Creates suggestions for the user to review
        """
        if not job_applications:
            return 0
        
        # Log the total number of job applications found
        logger.info(f"Processing {len(job_applications)} job applications for user {user.id}")
        
        # Get existing applications for this user
        existing_applications = list(mongo.db.applications.find({'user_id': str(user.id)}))
        
        # Get existing suggestions
        existing_suggestions = mongo.db.email_suggestions.find_one({
            'user_id': str(user.id),
            'processed': False
        })
        
        # Extract existing suggestion details to avoid duplicates
        existing_suggestion_details = set()
        if existing_suggestions:
            for suggestion in existing_suggestions['suggestions']:
                if suggestion['type'] == 'new':
                    # For new applications, use company + position as key (ignoring case)
                    key = f"{suggestion.get('company', '').lower()}:{suggestion.get('position', '').lower()}"
                    existing_suggestion_details.add(key)
                elif suggestion['type'] == 'update':
                    # For updates, use application_id + new_status as key
                    key = f"{suggestion.get('application_id', '')}:{suggestion.get('new_status', '')}"
                    existing_suggestion_details.add(key)
        
        # Define status priority (higher number = higher priority)
        status_priority = {
            'Applied': 1,
            'In Progress': 2,
            'Interview': 3,
            'Offer': 4,
            'Rejected': 5
        }
        
        # Track processed emails to avoid duplicates
        processed_emails = set()
        processed_companies_positions = set()  # Track company+position combinations
        
        # Group applications by company and position to avoid duplicates
        company_position_groups = {}
        
        # First pass: group applications by company and position
        for job_app in job_applications:
            try:
            # Skip if not job-related (double-check)
            if not job_app.get('is_job_related', True):
                continue
            
            # Create a unique identifier for this email to avoid duplicates
            email_id = job_app.get('email_id', '')
            subject = job_app.get('subject', '')
            email_key = f"{email_id}:{subject}"
            
            # Skip if we've already processed this email
            if email_key in processed_emails:
                logger.info(f"Skipping duplicate email: {subject}")
                continue
            
            processed_emails.add(email_key)
            
                # Get basic information from the job application
                company = job_app.get('company', 'Unknown Company')
                position = job_app.get('position', 'Unknown Position')
                status = job_app.get('status', 'Applied')
                confidence = job_app.get('confidence', 0.5)
                from_email = job_app.get('from_email', '')
                
                # Extra verification - don't process emails that are actually marketing or newsletter with low confidence
                if 'tesla' in company.lower() and ('model' in subject.lower() or 'update' in subject.lower()):
                    logger.info(f"Skipping Tesla marketing email: {subject}")
                    continue
                    
                if job_app.get('confidence', 1.0) < 0.7 and ('newsletter' in subject.lower() or 'update' in subject.lower()):
                    logger.info(f"Skipping likely newsletter: {subject}")
                    continue
                    
                # Try to clean up company names from domains
                if company == "Unknown Company" or company in ['Job Application', 'Job Opportunity']:
                    # Try various extraction methods
                    from_email = job_app.get('from_email', '')
                    subject_text = job_app.get('subject', '')
                    body_text = job_app.get('body', '')
                    
                    # Try various company extraction methods
                    extracted_company = EmailService._extract_company_from_email_content(subject_text, from_email)
                    if extracted_company and extracted_company != "Unknown Company":
                        company = extracted_company
                        logger.info(f"Using email content derived company name: {company}")
                    else:
                        # Fall back to domain as last resort
                        domain_company = EmailService._extract_company_from_domain(from_email)
                        if domain_company and domain_company != "Unknown Company":
                            company = domain_company
                            logger.info(f"Using domain-derived company name: {company}")
                        elif 'job' in subject.lower() or 'application' in subject.lower() or 'position' in subject.lower():
                            # Use a generic name that won't cause rendering issues
                            company = "Job Application"
                            logger.info(f"Using generic job application label for company")
                            
                # Clean up position
                if position == "Unknown Position" or position == "Job Opportunity":
                    # Try to extract from subject and body
                    subject_position = EmailService._extract_position_from_subject(subject)
                    if subject_position and subject_position != "Unknown Position":
                        position = subject_position
                        logger.info(f"Using subject-derived position: {position}")
                    else:
                        # Try to extract from body
                        body_text = job_app.get('body', '')
                        content_position = EmailService._extract_position_from_email_content(subject, body_text)
                        if content_position != "Unknown Position":
                            position = content_position
                            logger.info(f"Using content-derived position: {position}")
                        elif 'job' in subject.lower() or 'application' in subject.lower() or 'position' in subject.lower():
                            # Use the subject as a fallback for position
                            position = f"Position from: {subject[:40]}" if len(subject) > 0 else "Job Opportunity"
                            logger.info(f"Using email subject as position")
                
                # Generate a key for grouping
                company_position_key = f"{company.lower()}:{position.lower()}"
                
                # If we still don't have a valid company or position, see if we can use email subject as a last resort
                if (company == "Unknown Company" or company in ['Job Application', 'Job Opportunity']) and position == "Unknown Position":
                    # Use the email subject directly if it's not too long
                    if len(subject) < 60 and ('job' in subject.lower() or 'application' in subject.lower() or 'position' in subject.lower() or 'interview' in subject.lower()):
                        position = f"Position: {subject[:40]}"  # Limit length
                        company = "Job Application"
                        company_position_key = f"subject:{subject.lower()}"
                        logger.info(f"Using email subject as position: {position}")
                    else:
                        # If we still have no company or position, make one last attempt with generic labels
                        if 'job' in subject.lower() or 'application' in subject.lower() or 'interview' in subject.lower() or 'offer' in subject.lower():
                            company = "Job Application"
                            position = "Position from Email"
                            company_position_key = f"generic:{from_email.lower()}"
                            logger.info("Using generic job application label")
                        else:
                            logger.info(f"Skipping suggestion with unknown company AND position and no job indicators: {company} - {position}")
                            continue
                
                # Only skip if we've processed this company/position combo OR the combination is in existing suggestions
                if company_position_key in processed_companies_positions or company_position_key in existing_suggestion_details:
                    logger.info(f"Skipping duplicate company/position: {company} - {position}")
                    continue
                    
                processed_companies_positions.add(company_position_key)
                
                # Add to group or create new group
                if company_position_key not in company_position_groups:
                    company_position_groups[company_position_key] = {
                        'company': company,
                        'position': position,
                        'emails': [],
                        'best_status': None,
                        'best_status_priority': -1,
                        'best_confidence': 0,
                        'latest_timestamp': None,
                        'latest_email': None
                    }
                
                # Add this email to the group
                timestamp = job_app.get('timestamp', datetime.now())
                if isinstance(timestamp, str):
                    try:
                        timestamp = datetime.fromisoformat(timestamp)
                    except ValueError:
                        timestamp = datetime.now()
                        
                company_position_groups[company_position_key]['emails'].append(job_app)
                
                # Update best status if this email has higher priority
                status_priority_value = status_priority.get(status, 0)
                if status_priority_value > company_position_groups[company_position_key]['best_status_priority']:
                    company_position_groups[company_position_key]['best_status'] = status
                    company_position_groups[company_position_key]['best_status_priority'] = status_priority_value
                    company_position_groups[company_position_key]['best_confidence'] = confidence
                    
                # Update latest timestamp
                if not company_position_groups[company_position_key]['latest_timestamp'] or timestamp > company_position_groups[company_position_key]['latest_timestamp']:
                    company_position_groups[company_position_key]['latest_timestamp'] = timestamp
                    company_position_groups[company_position_key]['latest_email'] = job_app
            except Exception as e:
                logger.error(f"Error processing job app: {str(e)}")
                continue
        
        # Now process each group to create suggestions
        suggestions = []
        
        for group_key, group_data in company_position_groups.items():
            try:
                company = group_data['company']
                position = group_data['position']
                status = group_data['best_status'] or 'Applied'  # Default to Applied if None
                latest_email = group_data['latest_email']
                
                if not latest_email:
                    logger.error(f"Missing latest email for {company} - {position}")
                continue
            
            # Prepare notes with application platform if available
                notes = latest_email.get('notes', '')
                application_platform = latest_email.get('application_platform', '')
                email_subject = latest_email.get('subject', '')
            
            if application_platform:
                if notes:
                    notes = f"Applied via {application_platform}. {notes}"
                else:
                    notes = f"Applied via {application_platform}."
            
                # If notes is still empty, add the email subject
                if not notes and email_subject:
                    notes = f"From email: {email_subject}"
        
                # Check if this company+position combination exists in user's applications
            matching_apps = [
                app for app in existing_applications 
                    if app['company'].lower() == company.lower() and
                    (
                        app['position'].lower() == position.lower() or
                        # Try less strict matching for position
                        EmailService._position_similarity(app['position'], position) > 0.7
                    )
                ]
                
                current_time = datetime.now()
                suggestion_timestamp = latest_email.get('timestamp', current_time)
                
                # Ensure timestamp is a datetime object
                if isinstance(suggestion_timestamp, str):
                    try:
                        suggestion_timestamp = datetime.fromisoformat(suggestion_timestamp)
                    except (ValueError, TypeError):
                        suggestion_timestamp = current_time
            
            if matching_apps:
                    # Found matching applications, check if status update needed
                for app in matching_apps:
                        app_status = app.get('status')
                        
                        # Only suggest status change if the email status is different and has higher priority
                        if (app_status != status and 
                            status_priority.get(status, 0) > status_priority.get(app_status, 0)):
                            
                            # Create suggestion for status update
                            suggestion = {
                                'type': 'update',
                                'application_id': app['_id'],
                                'company': company,
                                'position': position,
                                'current_status': app_status,
                                'new_status': status,
                                'email_subject': email_subject,
                                'notes': notes,
                                'source': 'email',
                                'timestamp': suggestion_timestamp,
                                'date': suggestion_timestamp,  # For backward compatibility
                                'confidence': group_data['best_confidence']
                            }
                            
                            # Avoid duplicate suggestions
                            suggestion_key = f"{app['_id']}:{status}"
                            if suggestion_key not in existing_suggestion_details:
                                suggestions.append(suggestion)
                            existing_suggestion_details.add(suggestion_key)
                            
                            # Only update one application if multiple matches found
                            break
                else:
                    # No matching application, create new application suggestion
                    suggestion = {
                        'type': 'new',
                        'company': company,
                        'position': position,
                        'status': status,
                        'url': latest_email.get('job_url', ''),
                        'date_applied': suggestion_timestamp,
                        'notes': notes,
                        'email_subject': email_subject,
                        'source': 'email',
                        'timestamp': suggestion_timestamp,
                        'date': suggestion_timestamp,  # For backward compatibility
                        'confidence': group_data['best_confidence'],
                        'job_url': latest_email.get('job_url', ''),  # Add job URL to new suggestions
                        'deadline': latest_email.get('deadline', None),  # Include any deadline info
                    }
                    
                    # Avoid duplicate suggestions
                    suggestion_key = f"{company.lower()}:{position.lower()}"
                    if suggestion_key not in existing_suggestion_details:
                        suggestions.append(suggestion)
                    existing_suggestion_details.add(suggestion_key)
            except Exception as e:
                logger.error(f"Error creating suggestion: {str(e)}")
                    continue
                
        # Create or update email suggestions document
        if suggestions:
            try:
            if existing_suggestions:
                    # Add new suggestions to existing ones
                    existing_suggestions['suggestions'].extend(suggestions)
                mongo.db.email_suggestions.update_one(
                    {'_id': existing_suggestions['_id']},
                        {'$set': {'suggestions': existing_suggestions['suggestions']}}
                )
            else:
                # Create new suggestions document
                    email_suggestions = {
                    'user_id': str(user.id),
                    'suggestions': suggestions,
                    'processed': False,
                        'created_at': datetime.now()
                    }
                    mongo.db.email_suggestions.insert_one(email_suggestions)
            except Exception as e:
                logger.error(f"Error saving suggestions: {str(e)}")
            
            logger.info(f"Created {len(suggestions)} suggestions out of {len(job_applications)} job applications for user {user.id}")
        return len(suggestions)
    
    @staticmethod
    def _position_similarity(position1, position2):
        """
        Calculate similarity between two job positions
        Uses word overlap and partial matching
        """
        if not position1 or not position2:
            return 0
            
        # Normalize positions
        pos1 = position1.lower()
        pos2 = position2.lower()
        
        # Exact match
        if pos1 == pos2:
            return 1.0
            
        # One is substring of the other
        if pos1 in pos2 or pos2 in pos1:
            shorter = min(len(pos1), len(pos2))
            longer = max(len(pos1), len(pos2))
            return shorter / longer
        
        # Word overlap
        words1 = set(pos1.split())
        words2 = set(pos2.split())
        
        common_words = words1.intersection(words2)
        total_words = words1.union(words2)
        
        if not total_words:
            return 0
            
        return len(common_words) / len(total_words)
    
    @staticmethod
    def clear_analysis_cache(user_id=None, older_than_days=None):
        """
        Clear the email analysis cache
        
        Args:
            user_id (str): If provided, only clear cache for this user
            older_than_days (int): If provided, only clear cache entries older than this many days
            
        Returns:
            int: Number of cache entries deleted
        """
        query = {}
        
        # Filter by user if specified
        if user_id:
            query["user_id"] = str(user_id)
        
        # Filter by age if specified
        if older_than_days:
            cutoff_date = datetime.utcnow() - timedelta(days=older_than_days)
            query["created_at"] = {"$lt": cutoff_date}
        
        try:
            # Delete matching cache entries
            result = mongo.db.analysis_cache.delete_many(query)
            return result.deleted_count
        except Exception as e:
            logger.error(f"Error clearing cache: {str(e)}")
            return 0
    
    @staticmethod
    def ensure_cache_indexes():
        """
        Ensure that the necessary indexes exist on the analysis_cache collection
        This includes a TTL index for automatic expiration of cache entries
        """
        try:
            # Create TTL index on created_at field to automatically expire cache entries after 30 days
            mongo.db.analysis_cache.create_index(
                [("created_at", 1)], 
                expireAfterSeconds=30 * 24 * 60 * 60,  # 30 days in seconds
                background=True
            )
            
            # Create index on user_id for faster queries
            mongo.db.analysis_cache.create_index([("user_id", 1)], background=True)
            
            # Create index on is_job_related for faster filtering
            mongo.db.analysis_cache.create_index([("is_job_related", 1)], background=True)
            
            logger.info("Cache indexes created successfully")
        except Exception as e:
            logger.error(f"Error creating cache indexes: {str(e)}")
    
    @staticmethod
    def schedule_cache_cleanup():
        """Schedule cache cleanup task."""
        def cleanup():
            while True:
                EmailService._cleanup_expired_cache()
                time.sleep(3600)  # Run every hour

        thread = threading.Thread(target=cleanup, daemon=True)
        thread.start()

    @staticmethod
    def clear_all_user_data(user):
        """
        Clear all email suggestions, applications, and cache for a user
        This is useful for testing and starting fresh
        
        Args:
            user: The user object
            
        Returns:
            dict: Counts of deleted items
        """
        try:
            user_id = str(user.id)
            
            # Clear email suggestions
            suggestions_result = mongo.db.email_suggestions.delete_many({'user_id': user_id})
            
            # Clear applications
            applications_result = mongo.db.applications.delete_many({'user_id': user_id})
            
            # Clear analysis cache
            cache_result = mongo.db.analysis_cache.delete_many({'user_id': user_id})
            
            # Reset last scan time
            user_update_result = mongo.db.users.update_one(
                {'_id': ObjectId(user_id)},
                {'$unset': {'email_settings.last_scan': ''}}
            )
            
            return {
                'suggestions': suggestions_result.deleted_count,
                'applications': applications_result.deleted_count,
                'cache': cache_result.deleted_count
            }
        except Exception as e:
            logger.error(f"Error clearing user data: {str(e)}")
            return {
                'suggestions': 0,
                'applications': 0,
                'cache': 0
            } 

    @staticmethod
    def _extract_company_from_domain(from_email):
        """Extract company name from email domain"""
        if not from_email:
            return "Unknown Company"
            
        try:
            # Extract domain
            domain_match = re.search(r'@([^.]+)', from_email)
            if not domain_match:
                return "Unknown Company"
                
            domain = domain_match.group(1)
            
            # Skip common email providers and job boards
            common_email_providers = [
                'gmail', 'yahoo', 'hotmail', 'outlook', 'aol', 'icloud', 
                'protonmail', 'mail', 'me', 'live', 'msn', 'ymail', 'inbox'
            ]
            
            job_boards = [
                'indeed', 'linkedin', 'ziprecruiter', 'glassdoor', 'monster', 
                'careerbuilder', 'dice', 'simplyhired', 'applytojob', 'lever', 
                'greenhouse', 'workday', 'taleo', 'jobvite', 'smartrecruiters',
                'recruiter', 'talent', 'jobsearch', 'careers', 'jobs'
            ]
            
            # Check if it's a job board - if so, try to extract the company from the email content rather than using the domain
            if domain.lower() in job_boards:
                return "Unknown Company"  # Don't use the job board as the company
                
            if domain.lower() in common_email_providers:
                return "Unknown Company"
                
            # Format domain as company name
            return domain.title()
        except Exception as e:
            logger.error(f"Error extracting company from domain: {str(e)}")
            return "Unknown Company"

    @staticmethod
    def _extract_position_from_subject(subject):
        """
        Extract job position from email subject
        Enhanced with better pattern matching
        """
        if not subject:
            return "Unknown Position"
            
        try:
            # Common patterns for subject lines with positions
            position_subject_patterns = [
                # Application received patterns
                r'(?:your|re:|application|applied|regarding) (?:for|to) (?:the )?(?:position|role|job)(?: of| as)? ([A-Za-z0-9\s\-\&\.\+\/\(\)]+?)(?:at|\-|\.|$)',
                r'(?:application|applied) (?:for|to) ([A-Za-z0-9\s\-\&\.\+\/\(\)]+?) (?:position|role|job)',
                
                # Thank you patterns
                r'(?:thank you|thanks) (?:for|on) (?:your|the) (?:application|interest|applying) (?:for|to|in) (?:the )?(?:position|role|job)(?: of| as)? ([A-Za-z0-9\s\-\&\.\+\/\(\)]+?)(?:at|\-|\.|$)',
                r'(?:thank you|thanks) (?:for|on) (?:your|the) (?:application|interest|applying) (?:for|to|in) (?:the )?([A-Za-z0-9\s\-\&\.\+\/\(\)]+?) (?:position|role|job)',
                
                # Position announcement patterns
                r'(?:position|job|opening|opportunity)(?: for| as)? ([A-Za-z0-9\s\-\&\.\+\/\(\)]+?)(?:at|\-|\.|$)',
                r'([A-Za-z0-9\s\-\&\.\+\/\(\)]+?) (?:position|role|job)(?: at| -|\.|$)',
                
                # Job title + company patterns
                r'([A-Za-z0-9\s\-\&\.\+\/\(\)]+?) (?:at|with|for) ([A-Za-z0-9\s\-\&\.\+\/\(\)]+?)(?:$|\.|:|\-)',
                
                # Interview patterns
                r'(?:interview|next steps) (?:for|regarding) (?:the )?(?:position|role|job)(?: of| as)? ([A-Za-z0-9\s\-\&\.\+\/\(\)]+?)(?:at|\-|\.|$)',
                r'(?:interview|next steps) (?:for|regarding) (?:the )?([A-Za-z0-9\s\-\&\.\+\/\(\)]+?) (?:position|role|job)',
                
                # Status update patterns
                r'(?:status|update|regarding) (?:your|the) (?:application|candidacy) (?:for|to) (?:the )?(?:position|role|job)(?: of| as)? ([A-Za-z0-9\s\-\&\.\+\/\(\)]+?)(?:at|\-|\.|$)',
                r'(?:status|update|regarding) (?:your|the) (?:application|candidacy) (?:for|to) (?:the )?([A-Za-z0-9\s\-\&\.\+\/\(\)]+?) (?:position|role|job)',
                
                # Direct job titles (more aggressive matching)
                r'^re: ([A-Z][A-Za-z0-9\s\-\&\.\+\/\(\)]{2,40})$',  # RE: Software Engineer
                r'^([A-Z][A-Za-z0-9\s\-\&\.\+\/\(\)]{2,40}) (?:position|role|job|opportunity)$',  # Software Engineer position
                r'^(?:job|position): ([A-Z][A-Za-z0-9\s\-\&\.\+\/\(\)]{2,40})$',  # Job: Software Engineer
            ]

            # Try all patterns
            for pattern in position_subject_patterns:
                match = re.search(pattern, subject, re.IGNORECASE)
                if match:
                    position = match.group(1).strip()
                    # Validate position - must be at least 2 characters
                    if len(position) > 2:
                        # Clean up position
                        position = re.sub(r'[,\.]$', '', position)  # Remove trailing commas and periods
                        # Avoid extremely long position titles (likely to be phrases, not positions)
                        if len(position) > 50:
                            words = position.split()
                            if len(words) > 7:  # Too many words
                                position = ' '.join(words[:6])  # Use first 6 words
                        
                        # Ensure proper capitalization
                        position = ' '.join(word.capitalize() if len(word) > 3 else word for word in position.split())
                        return position
                    
            # If no specific pattern matched, try to extract any job title from the subject
            # Common titles that might appear in emails
            common_titles = [
                'Software Engineer', 'Product Manager', 'Data Scientist', 'Web Developer', 
                'Frontend Developer', 'Backend Developer', 'Full Stack Developer', 'DevOps Engineer',
                'QA Engineer', 'UI/UX Designer', 'UX Designer', 'UI Designer', 'Graphic Designer',
                'Project Manager', 'Marketing Manager', 'Sales Representative', 'Account Manager',
                'Financial Analyst', 'Accountant', 'HR Manager', 'Operations Manager', 'Executive Assistant',
                'Customer Support', 'Technical Writer', 'Content Writer', 'Content Strategist',
                'Business Analyst', 'Data Analyst', 'Systems Administrator', 'Network Engineer',
                'Product Designer', 'Research Scientist', 'Machine Learning Engineer'
            ]
            
            # Check if any common titles appear in the subject
            subject_lower = subject.lower()
            for title in common_titles:
                if title.lower() in subject_lower:
                    # Found a title match
                    return title
                    
            # If still no position found but subject contains "engineer", "manager", etc.
            common_suffixes = ['Engineer', 'Manager', 'Developer', 'Designer', 'Analyst', 'Specialist', 'Coordinator', 'Assistant']
            for suffix in common_suffixes:
                suffix_pattern = r'([A-Za-z\s\-\&\.]{3,25})' + suffix
                match = re.search(suffix_pattern, subject, re.IGNORECASE)
                if match:
                    prefix = match.group(1).strip()
                    if len(prefix) > 2:
                        position = f"{prefix} {suffix}"
                        return position
            
            return "Unknown Position"
        except Exception as e:
            logger.error(f"Error extracting position from subject: {str(e)}")
            return "Unknown Position"

    @staticmethod
    def _extract_position_from_email_content(subject, body):
        """
        Extract position from email content using robust pattern matching
        Looks for common position patterns in both subject and body
        """
        if not subject and not body:
            return "Unknown Position"
            
        try:
            # Check subject first (higher priority)
            subject_position = EmailService._extract_position_from_subject(subject)
            if subject_position != "Unknown Position":
                return subject_position
                
            # If not found in subject, search body with specific patterns
            if not body:
                return "Unknown Position"
                
            # Normalize body text
            body = body.replace('\n', ' ').replace('\r', ' ')
            
            # Common patterns for positions in email body
            position_body_patterns = [
                # Specific job position patterns
                r'(?:position|job|role)(?: of| as| for)? ([A-Za-z0-9\s\-\&\.\+\/\(\)]{3,40})(?:\.|\,|\n|$)',
                r'(?:applied|applying|application) (?:for|to) (?:the )?(?:position|job|role)(?: of| as)? ([A-Za-z0-9\s\-\&\.\+\/\(\)]{3,40})(?:\.|\,|\n|$)',
                r'(?:applied|applying|application) (?:for|to) (?:the )?([A-Za-z0-9\s\-\&\.\+\/\(\)]{3,40}) (?:position|job|role)(?:\.|\,|\n|$)',
                r'(?:interview|consideration) (?:for|regarding) (?:the )?(?:position|job|role)(?: of| as)? ([A-Za-z0-9\s\-\&\.\+\/\(\)]{3,40})(?:\.|\,|\n|$)',
                r'(?:regarding|about) (?:your|the) ([A-Za-z0-9\s\-\&\.\+\/\(\)]{3,40}) (?:position|job|role|opportunity)(?:\.|\,|\n|$)',
                r'(?:title|role) (?:is|of) ([A-Za-z0-9\s\-\&\.\+\/\(\)]{3,40})(?:\.|\,|\n|$)',
                
                # After title/position/role keywords
                r'(?:job title|position title|job role|position|role)(?:\:|\s+is\s+|\s+-\s+|\s+as\s+)([A-Za-z0-9\s\-\&\.\+\/\(\)]{3,40})(?:\.|\,|\n|$)'
            ]
            
            # Try all patterns
            for pattern in position_body_patterns:
                match = re.search(pattern, body, re.IGNORECASE)
                if match:
                    position = match.group(1).strip()
                    # Validate position - must be at least 3 characters
                    if len(position) > 2:
                        # Clean up position
                        position = re.sub(r'[,\.]$', '', position)  # Remove trailing commas and periods
                        # Validate position is not too long
                        if len(position) > 50:
                            return "Unknown Position"  # Likely matched too much text
                        return position
                        
            # Common titles that might appear in the body
            common_titles = [
                'Software Engineer', 'Product Manager', 'Data Scientist', 'Web Developer', 
                'Frontend Developer', 'Backend Developer', 'Full Stack Developer', 'DevOps Engineer',
                'QA Engineer', 'UI/UX Designer', 'UX Designer', 'UI Designer', 'Graphic Designer',
                'Project Manager', 'Marketing Manager', 'Sales Representative', 'Account Manager',
                'Financial Analyst', 'Accountant', 'HR Manager', 'Operations Manager', 'Executive Assistant',
                'Customer Support', 'Technical Writer', 'Content Writer', 'Content Strategist',
                'Business Analyst', 'Data Analyst', 'Systems Administrator', 'Network Engineer',
                'Product Designer', 'Research Scientist', 'Machine Learning Engineer'
            ]
            
            # Check if any common titles appear in the body
            body_lower = body.lower()
            for title in common_titles:
                if title.lower() in body_lower:
                    context_before = body_lower.split(title.lower())[0][-30:] if title.lower() in body_lower else ""
                    context_after = body_lower.split(title.lower())[1][:30] if title.lower() in body_lower else ""
                    
                    # Check if this is actually a job title mention (look for contextual clues)
                    job_context_clues = ['position', 'job', 'role', 'title', 'applied', 'application', 'interview']
                    if any(clue in context_before or clue in context_after for clue in job_context_clues):
                        return title
            
            return "Unknown Position"
        except Exception as e:
            logger.error(f"Error extracting position from email content: {str(e)}")
            return "Unknown Position"

    @staticmethod
    def _extract_company_from_email_content(subject, from_email):
        """
        Extract company name from email subject and sender
        More sophisticated than the domain extraction
        """
        try:
            # First try to extract from "from" email display name
            # E.g., "Company Name <email@domain.com>"
            sender_match = re.search(r'^([^<]+)', from_email)
            if sender_match:
                sender_name = sender_match.group(1).strip()
                # Check if sender name looks like a company
                if (len(sender_name.split()) > 1 and 
                    not any(word.lower() in ['no-reply', 'noreply', 'do-not-reply', 'donotreply'] for word in sender_name.split()) and
                    any(word[0].isupper() for word in sender_name.split())):
                    
                    # Filter out common patterns for automated emails
                    if not any(x in sender_name.lower() for x in ['team', 'notifications', 'alert', 'update', 'system', 'recruiter']):
                        return sender_name
                    
            # Try to extract company from subject with patterns
            subject_patterns = [
                r'job (?:at|with) ([A-Z][A-Za-z0-9\s&\.\-\']+)',
                r'([A-Z][A-Za-z0-9\s&\.\-\']+) job',
                r'application (?:at|for|with) ([A-Z][A-Za-z0-9\s&\.\-\']+)',
                r'([A-Z][A-Za-z0-9\s&\.\-\']+) application',
                r'interview (?:at|with) ([A-Z][A-Za-z0-9\s&\.\-\']+)',
                r'([A-Z][A-Za-z0-9\s&\.\-\']+) interview',
                r'position (?:at|with) ([A-Z][A-Za-z0-9\s&\.\-\']+)',
                r'([A-Z][A-Za-z0-9\s&\.\-\']+) position',
                r'offer from ([A-Z][A-Za-z0-9\s&\.\-\']+)',
                r'([A-Z][A-Za-z0-9\s&\.\-\']+) offer'
            ]
            
            for pattern in subject_patterns:
                match = re.search(pattern, subject, re.IGNORECASE)
                if match:
                    company_name = match.group(1).strip()
                    # Validate company name
                    if len(company_name) >= 2 and not company_name.lower() in ['job', 'position', 'application', 'interview', 'company']:
                        return company_name
            
            return "Unknown Company"
        
        except Exception as e:
            logger.error(f"Error extracting company from content: {str(e)}")
            return "Unknown Company"